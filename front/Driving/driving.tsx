import React, { useRef, useState, useEffect } from "react";
import { View, Button, StyleSheet, Text, Alert, Modal, ActivityIndicator } from "react-native";
import { Camera, CameraView } from "expo-camera";
import { Audio } from "expo-av";
import * as Speech from "expo-speech";
import AsyncStorage from "@react-native-async-storage/async-storage";
import { useNavigation, CommonActions } from "@react-navigation/native";
import { useWebSocket } from "./context/WebSocketContext";
import { fileUriToArrayBuffer, zipSingleFileIfAvailable } from "../utils/wsHelpers";

// â˜… í™”ë©´ íšŒì „ ì œì–´ ë¼ì´ë¸ŒëŸ¬ë¦¬
import * as ScreenOrientation from 'expo-screen-orientation';

const HOST = "15.165.244.204:8080"; // ë°±ì—”ë“œ ì£¼ì†Œ
const API_URL = `http://${HOST}`;

export default function Driving() {
  const navigation = useNavigation<any>();
  const cameraRef = useRef<CameraView | null>(null);
  const { connect, close, sendJson, sendBinary, onceOpen, ref: wsRef } = useWebSocket();

  const [jwt, setJwt] = useState<string | null>(null);
  const [recording, setRecording] = useState(false);
  const [elapsedTime, setElapsedTime] = useState(0);
  
  // ë°±ì—”ë“œì—ì„œ ë°›ì€ recordId ì €ì¥
  const currentRecordIdRef = useRef<number | null>(null);

  const drivingLoopRef = useRef(false);
  const timerRef = useRef<NodeJS.Timeout | null>(null);
  const [camPerm, setCamPerm] = useState(false);
  const [audPerm, setAudPerm] = useState(false);
  const [cameraReady, setCameraReady] = useState(false);

  const [stopping, setStopping] = useState(false);
  const [statusMessage, setStatusMessage] = useState(""); 

  // ----------------------------------------------------------------
  // â˜… [ìˆ˜ì •] í™”ë©´ ê°€ë¡œ ëª¨ë“œ(ë°˜ëŒ€ ë°©í–¥) ê³ ì • & íƒ­ë°” ìˆ¨ê¸°ê¸°
  // ----------------------------------------------------------------
  useEffect(() => {
    const lockLandscapeAndHideTab = async () => {
      try {
        // 1. íƒ­ë°” ìˆ¨ê¸°ê¸° (ë¶€ëª¨ ë„¤ë¹„ê²Œì´í„°ì¸ Tab.Navigatorì— ì˜µì…˜ ì„¤ì •)
        navigation.getParent()?.setOptions({
          tabBarStyle: { display: "none" }
        });

        // 2. ê°€ë¡œ ëª¨ë“œ ê³ ì • (LANDSCAPE_LEFT: ìœ—ë¶€ë¶„ì´ ì™¼ìª½)
        await ScreenOrientation.lockAsync(ScreenOrientation.OrientationLock.LANDSCAPE_LEFT);
      } catch (e) {
        console.warn("í™”ë©´ ì„¤ì • ì‹¤íŒ¨:", e);
      }
    };

    lockLandscapeAndHideTab();

    // í™”ë©´ì„ ë²—ì–´ë‚  ë•Œ(Unmount) ì›ìƒë³µêµ¬
    return () => {
      const restoreScreen = async () => {
        try {
          // 1. ì„¸ë¡œ ëª¨ë“œë¡œ ë³µê·€
          await ScreenOrientation.lockAsync(ScreenOrientation.OrientationLock.PORTRAIT_UP);
          
          // 2. íƒ­ë°” ë‹¤ì‹œ ë³´ì´ê¸°
          navigation.getParent()?.setOptions({
            tabBarStyle: undefined // ê¸°ë³¸ê°’ìœ¼ë¡œ ë³µì› (ë³´ì„)
          });
        } catch (e) {
          console.warn("í™”ë©´ ë³µêµ¬ ì‹¤íŒ¨:", e);
        }
      };
      restoreScreen();
    };
  }, [navigation]);
  // ----------------------------------------------------------------


  // 1. í† í° ë¡œë“œ
  useEffect(() => {
    (async () => {
      const token = await AsyncStorage.getItem("accessToken");
      if (!token) {
        Alert.alert("ë¡œê·¸ì¸ í•„ìš”", "ë‹¤ì‹œ ë¡œê·¸ì¸í•´ì£¼ì„¸ìš”.");
        return;
      }
      setJwt(token);
    })();
  }, []);

  // 2. ê¶Œí•œ ìš”ì²­
  useEffect(() => {
    (async () => {
      const { status: cs } = await Camera.requestCameraPermissionsAsync();
      setCamPerm(cs === "granted");
      const { status: ms } = await Camera.requestMicrophonePermissionsAsync();
      setAudPerm(ms === "granted");
      
      await Audio.setAudioModeAsync({
        allowsRecordingIOS: true,
        playsInSilentModeIOS: true,
        shouldDuckAndroid: true,
        playThroughEarpieceAndroid: false,
      });
    })();
  }, []);

  // 3. íƒ€ì´ë¨¸
  useEffect(() => {
    if (recording && !timerRef.current)
      timerRef.current = setInterval(() => setElapsedTime((t) => t + 1), 1000);
    return () => {
      if (timerRef.current) {
        clearInterval(timerRef.current);
        timerRef.current = null;
      }
    };
  }, [recording]);

  // 4. WebSocket ë©”ì‹œì§€ ë¦¬ìŠ¤ë„ˆ (RecordID íšë“ + TTS ìŒì„± í”¼ë“œë°±)
  useEffect(() => {
    const ws = wsRef.current;
    if (!ws) return;

    const handleMessage = (e: WebSocketMessageEvent) => {
      try {
        const msg = JSON.parse(e.data);

        // (1) ì£¼í–‰ ì‹œì‘ ë©”ì‹œì§€
        if (msg.type === 'STARTED' && msg.recordId) {
          console.log("[WS] âœ… ì£¼í–‰ ì‹œì‘ë¨! RecordID:", msg.recordId);
          currentRecordIdRef.current = msg.recordId;
        }

        // (2) AI ìŒì„± í”¼ë“œë°± ì²˜ë¦¬ (TTS)
        if (msg.type === 'FEEDBACK_VOICE' && msg.message) {
          console.log("ğŸ”Š [TTS] ìŒì„± ì•ˆë‚´:", msg.message);
          
          Speech.stop(); // ê¸°ì¡´ ìŒì„± ì¤‘ë‹¨

          Speech.speak(msg.message, {
            language: "ko-KR",
            pitch: 1.0,
            rate: 1.0,
          });
        }

      } catch (err) {
        // ignore
      }
    };

    ws.addEventListener('message', handleMessage);
    return () => ws.removeEventListener('message', handleMessage);
  }, [wsRef.current, recording]);


  const formatTime = (n: number) =>
    `${String(Math.floor(n / 60)).padStart(2, "0")}:${String(n % 60).padStart(2, "0")}`;

  // ì˜ìƒ ì¡°ê° ë…¹í™” (2ì´ˆ)
  const recordOneSegment = () =>
    new Promise<string>((resolve, reject) => {
      if (!cameraRef.current) return reject(new Error("camera not ready"));
      
      cameraRef.current
        .recordAsync({ maxDuration: 2 })
        .then((video) => {
          if (video?.uri) {
            resolve(video.uri);
          } else {
            reject(new Error("No video URI returned"));
          }
        })
        .catch((err) => {
          reject(err);
        });
    });

  // 5. ì£¼í–‰ ì¢…ë£Œ API í˜¸ì¶œ ë° ë„¤ë¹„ê²Œì´ì…˜ ë¦¬ì…‹
  const finishDrivingSequence = async () => {
    console.log("[Finish] ì£¼í–‰ ì¢…ë£Œ ìš”ì²­");
    setStatusMessage("ì£¼í–‰ ê¸°ë¡ ì €ì¥ ì¤‘...");
    
    try {
      if (currentRecordIdRef.current) {
        // ë°±ì—”ë“œì— ì¢…ë£Œ ìš”ì²­
        const response = await fetch(`${API_URL}/api/driving/end`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${jwt}`
            },
            body: JSON.stringify({
                recordId: currentRecordIdRef.current,
                endTime: new Date().toISOString(),
                finalScore: 100, // (ì˜ˆì‹œ) ì ìˆ˜
                finalVideoKeyOrUrl: null // ë°±ì—”ë“œê°€ ì§ì ‘ ë³‘í•©í•˜ë„ë¡ null ì „ì†¡
            })
        });
        
        if (response.ok) {
            console.log("[API] ì£¼í–‰ ì¢…ë£Œ ì„±ê³µ");
        } else {
            console.error("[API] ì£¼í–‰ ì¢…ë£Œ ì‹¤íŒ¨", await response.text());
        }
      }

    } catch (e) {
      console.error("[Finish] ì¢…ë£Œ ì—ëŸ¬:", e);
    } finally {
        setStopping(false);

        // ë„¤ë¹„ê²Œì´ì…˜ ë¦¬ì…‹ ë¡œì§
        navigation.getParent()?.navigate("ê¸°ë¡ì‹¤");
        navigation.dispatch(
          CommonActions.reset({
            index: 0,
            routes: [{ name: 'DrivingScreen' }], 
          })
        );
    }
  };


  // --- ë…¹í™” ì‹œì‘ ---
  const startRecording = async () => {
    if (recording) return;
    if (!camPerm || !audPerm) return Alert.alert("ê¶Œí•œ í•„ìš”", "ê¶Œí•œ í—ˆìš© í•„ìš”");
    if (!cameraReady || !cameraRef.current) return Alert.alert("ì¹´ë©”ë¼ ì¤€ë¹„ ì¤‘", "ì ì‹œë§Œìš”");
    if (!jwt) return Alert.alert("ì˜¤ë¥˜", "í† í° ì—†ìŒ");

    currentRecordIdRef.current = null;
    setStopping(false);

    try {
      Speech.speak("ì•ˆì „ ìš´ì „ì„ ì‹œì‘í•©ë‹ˆë‹¤.", { language: "ko-KR" });

      // ì›¹ì†Œì¼“ ì—°ê²°
      const url = `ws://${HOST}/ws/driving?token=${encodeURIComponent(`Bearer ${jwt}`)}`;
      await connect(url);
      await onceOpen();
      sendJson({ type: "START" }); 

      setRecording(true);
      setElapsedTime(0);
      drivingLoopRef.current = true;

      // ë…¹í™” ë£¨í”„
      let nextPromise: Promise<string> | null = null;
      
      while (drivingLoopRef.current) {
        // (A) ë…¹í™”
        const uri = nextPromise ? await nextPromise : await recordOneSegment();
        
        if (drivingLoopRef.current) {
             nextPromise = recordOneSegment();
        } else {
             nextPromise = null;
        }

        // (B) ì‹¤ì‹œê°„ ì „ì†¡
        const path = await zipSingleFileIfAvailable(uri);
        const buf = await fileUriToArrayBuffer(path);
        sendBinary(buf);
      }

    } catch (e) {
      console.warn("startRecording error:", e);
      Alert.alert("ì˜¤ë¥˜", "ë…¹í™” ì‹œì‘ ì‹¤íŒ¨");
      setRecording(false);
    }
  };

  // --- ë…¹í™” ì¢…ë£Œ ---
  const stopRecording = async () => {
    console.log("[Driving] ì¢…ë£Œ ë²„íŠ¼ í´ë¦­");
    if (!recording) return;
    
    Speech.stop();
    setStopping(true);
    
    drivingLoopRef.current = false; 
    
    try { cameraRef.current?.stopRecording(); } catch {}
    setRecording(false);

    // ì›¹ì†Œì¼“ END ì „ì†¡
    if (wsRef.current?.readyState === WebSocket.OPEN) {
        sendJson({ type: "END" });
    }
    close(); 

    // ì¢…ë£Œ API í˜¸ì¶œ
    await finishDrivingSequence();
  };

  return (
    <View style={{ flex: 1 }}>
      <CameraView
        ref={cameraRef}
        style={{ flex: 1 }}
        facing="back"
        mode="video"
        videoQuality="480p"
        onCameraReady={() => setCameraReady(true)}
      />

      <View style={styles.timeContainer}>
        <Text style={styles.timeText}>{formatTime(elapsedTime)}</Text>
      </View>

      <View style={styles.buttonContainer}>
        <Button
          title={recording ? "ì£¼í–‰ ì¢…ë£Œ" : "ì£¼í–‰ ì‹œì‘"}
          onPress={recording ? stopRecording : startRecording}
          disabled={stopping}
          color={recording ? "#DC2626" : "#3478F6"}
        />
      </View>

      {/* ì¢…ë£Œ ì¤‘ ë¡œë”© ëª¨ë‹¬ */}
      <Modal visible={stopping} transparent animationType="fade">
        <View style={styles.modalBackdrop}>
          <View style={styles.modalCard}>
            <ActivityIndicator size="large" color="#3478F6" />
            <Text style={styles.modalText}>ì£¼í–‰ ì¢…ë£Œ ì¤‘...</Text>
            <Text style={styles.modalSub}>{statusMessage}</Text>
          </View>
        </View>
      </Modal>
    </View>
  );
}

const styles = StyleSheet.create({
  buttonContainer: { position: "absolute", bottom: 40, alignSelf: "center", width: "80%" },
  timeContainer: {
    position: "absolute",
    top: 50,
    alignSelf: "center",
    backgroundColor: "rgba(0,0,0,0.5)",
    paddingHorizontal: 16,
    paddingVertical: 8,
    borderRadius: 20,
  },
  timeText: { fontSize: 24, fontWeight: "bold", color: "white" },
  modalBackdrop: {
    flex: 1,
    backgroundColor: "rgba(0,0,0,0.6)",
    justifyContent: "center",
    alignItems: "center",
  },
  modalCard: {
    width: 280,
    borderRadius: 16,
    backgroundColor: "white",
    paddingVertical: 28,
    paddingHorizontal: 24,
    alignItems: "center",
    elevation: 5,
  },
  modalText: { marginTop: 16, fontSize: 18, fontWeight: "bold", color: "#111827" },
  modalSub: { marginTop: 8, fontSize: 14, color: "#6B7280", textAlign: "center" },
});