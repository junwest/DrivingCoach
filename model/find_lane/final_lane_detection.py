#!/usr/bin/env python3
"""
ì°¨ì„  ì§€ì†ì„±(Persistence) ê¸°ë°˜ ì°¨ì„  ë³€ê²½ ê°ì§€
==============================================
ì°¨ì„ ì´ ì¼ì‹œì ìœ¼ë¡œ ì‚¬ë¼ì ¸ë„ ì´ì „ ìœ„ì¹˜ë¥¼ ìœ ì§€
ì‹¤ì œ ì°¨ì„  ë³€ê²½ë§Œ ì •í™•íˆ ê°ì§€
"""
import cv2
import numpy as np
from pathlib import Path
import json

def load_roi_config(video_name: str, output_dir: Path):
    config_path = output_dir / f"{video_name}_roi_config.json"
    if not config_path.exists():
        return None
    with open(config_path, 'r') as f:
        config = json.load(f)
    return np.float32(config['roi_points'])

def detect_lane_lines(bev_frame, exclude_bottom_height=50):
    """ì§ì„  ì°¨ì„  ê²€ì¶œ"""
    h, w = bev_frame.shape[:2]
    
    gray = cv2.cvtColor(bev_frame, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    edges = cv2.Canny(blurred, 50, 150)
    
    mask = np.ones_like(edges)
    mask[h - exclude_bottom_height:, :] = 0
    edges = cv2.bitwise_and(edges, mask)
    
    lines = cv2.HoughLinesP(
        edges,
        rho=1,
        theta=np.pi/180,
        threshold=30,
        minLineLength=40,
        maxLineGap=10
    )
    
    return lines, edges

def filter_vertical_lines(lines, min_angle=60, max_angle=120):
    """ìˆ˜ì§ì„  í•„í„°ë§"""
    if lines is None:
        return []
    
    vertical_lines = []
    for line in lines:
        x1, y1, x2, y2 = line[0]
        if x2 - x1 == 0:
            angle = 90
        else:
            angle = abs(np.degrees(np.arctan((y2 - y1) / (x2 - x1))))
        
        if min_angle <= angle <= max_angle:
            vertical_lines.append(line[0])
    
    return vertical_lines

def get_line_x_at_bottom(line, y_bottom, roi_top_y):
    """íŠ¹ì • y ìœ„ì¹˜ì—ì„œ ì„ ì˜ x ì¢Œí‘œ"""
    x1, y1, x2, y2 = line
    y_min = min(y1, y2)
    y_max = max(y1, y2)
    
    if y_max < y_bottom - 50:
        return None
    
    if y2 == y1:
        return x1
    
    x_at_bottom = x1 + (x2 - x1) * (y_bottom - y1) / (y2 - y1)
    return x_at_bottom

def find_lane_positions(vertical_lines, vehicle_x, h):
    """ì°¨ì„  ìœ„ì¹˜ ì°¾ê¸°"""
    if not vertical_lines:
        return None, None
    
    y_bottom = int(h * 0.85)
    roi_top = int(h * 0.6)
    
    line_x_positions = []
    for line in vertical_lines:
        x_pos = get_line_x_at_bottom(line, y_bottom, roi_top)
        if x_pos is not None:
            line_x_positions.append((x_pos, line))
    
    if not line_x_positions:
        return None, None
    
    line_x_positions.sort(key=lambda x: x[0])
    
    left_lines = [(x, l) for x, l in line_x_positions if x < vehicle_x]
    right_lines = [(x, l) for x, l in line_x_positions if x > vehicle_x]
    
    left_lane_x = left_lines[-1][0] if left_lines else None
    right_lane_x = right_lines[0][0] if right_lines else None
    
    return left_lane_x, right_lane_x

class LaneTracker:
    """ì°¨ì„  ìœ„ì¹˜ ì¶”ì  ë° ì§€ì†ì„± ê´€ë¦¬"""
    
    def __init__(self, persistence_frames=15, smooth_alpha=0.7):
        """
        Args:
            persistence_frames: ì°¨ì„ ì´ ì‚¬ë¼ì ¸ë„ ìœ ì§€í•  í”„ë ˆì„ ìˆ˜
            smooth_alpha: ìŠ¤ë¬´ë”© ê³„ìˆ˜ (0-1, 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìƒˆ ê°’ ì¤‘ì‹œ)
        """
        self.left_x = None
        self.right_x = None
        self.left_age = 0  # ë§ˆì§€ë§‰ ê°ì§€ ì´í›„ í”„ë ˆì„ ìˆ˜
        self.right_age = 0
        self.persistence_frames = persistence_frames
        self.smooth_alpha = smooth_alpha
    
    def update(self, detected_left, detected_right):
        """
        ì°¨ì„  ìœ„ì¹˜ ì—…ë°ì´íŠ¸ (ì§€ì†ì„± ë° ìŠ¤ë¬´ë”© ì ìš©)
        
        Returns:
            (left_x, right_x, left_confident, right_confident)
        """
        # ì™¼ìª½ ì°¨ì„  ì—…ë°ì´íŠ¸
        if detected_left is not None:
            if self.left_x is None:
                self.left_x = detected_left
            else:
                # ìŠ¤ë¬´ë”©: ì´ì „ ê°’ê³¼ ìƒˆ ê°’ì˜ ê°€ì¤‘ í‰ê· 
                self.left_x = self.smooth_alpha * detected_left + (1 - self.smooth_alpha) * self.left_x
            self.left_age = 0
        else:
            self.left_age += 1
            # persistence ê¸°ê°„ì´ ì§€ë‚˜ë©´ ì œê±°
            if self.left_age > self.persistence_frames:
                self.left_x = None
        
        # ì˜¤ë¥¸ìª½ ì°¨ì„  ì—…ë°ì´íŠ¸
        if detected_right is not None:
            if self.right_x is None:
                self.right_x = detected_right
            else:
                self.right_x = self.smooth_alpha * detected_right + (1 - self.smooth_alpha) * self.right_x
            self.right_age = 0
        else:
            self.right_age += 1
            if self.right_age > self.persistence_frames:
                self.right_x = None
        
        # ì‹ ë¢°ë„ (ìµœê·¼ ê°ì§€ì¼ìˆ˜ë¡ ë†’ìŒ)
        left_confident = self.left_x is not None and self.left_age < 5
        right_confident = self.right_x is not None and self.right_age < 5
        
        return self.left_x, self.right_x, left_confident, right_confident

def detect_lane_change(tracker, prev_center, threshold=40):
    """
    ì°¨ì„  ë³€ê²½ ê°ì§€ (ì°¨ì„  ì¤‘ì‹¬ì˜ ì´ë™ìœ¼ë¡œ íŒë‹¨)
    
    Args:
        tracker: Lane Tracker ê°ì²´
        prev_center: ì´ì „ ì°¨ì„  ì¤‘ì‹¬
        threshold: ì¤‘ì‹¬ ì´ë™ ì„ê³„ê°’
    
    Returns:
        (is_changing, direction, new_center)
    """
    if tracker.left_x is None or tracker.right_x is None:
        return False, None, prev_center
    
    # í˜„ì¬ ì°¨ì„  ì¤‘ì‹¬
    current_center = (tracker.left_x + tracker.right_x) / 2
    
    # ì´ì „ ì¤‘ì‹¬ì´ ì—†ìœ¼ë©´ ì´ˆê¸°í™”
    if prev_center is None:
        return False, None, current_center
    
    # ì¤‘ì‹¬ ì´ë™ëŸ‰
    center_shift = current_center - prev_center
    
    is_changing = False
    direction = None
    
    # ì„ê³„ê°’ ì´ìƒ ì´ë™í•˜ë©´ ì°¨ì„  ë³€ê²½
    if abs(center_shift) > threshold:
        is_changing = True
        if center_shift > 0:
            direction = 'to_right'  # ì¤‘ì‹¬ì´ ì˜¤ë¥¸ìª½ìœ¼ë¡œ â†’ ì°¨ëŸ‰ì€ ì˜¤ë¥¸ìª½ ì°¨ì„ ìœ¼ë¡œ
        else:
            direction = 'to_left'  # ì¤‘ì‹¬ì´ ì™¼ìª½ìœ¼ë¡œ â†’ ì°¨ëŸ‰ì€ ì™¼ìª½ ì°¨ì„ ìœ¼ë¡œ
    
    return is_changing, direction, current_center

def process_video_final(
    video_path: Path,
    output_path: Path,
    src_points: np.ndarray,
    lane_change_start_sec: float,
    lane_change_end_sec: float,
    vehicle_x: int = 200
):
    """ìµœì¢… ì°¨ì„  ë³€ê²½ ê°ì§€"""
    print(f"\nğŸ¥ Processing: {video_path.name}")
    print(f"   Expected lane change: {lane_change_start_sec}s ~ {lane_change_end_sec}s")
    
    dst_points = np.float32([[0, 0], [400, 0], [400, 600], [0, 600]])
    M = cv2.getPerspectiveTransform(src_points, dst_points)
    
    cap = cv2.VideoCapture(str(video_path))
    if not cap.isOpened():
        raise RuntimeError(f"Cannot open video: {video_path}")
    
    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    writer = cv2.VideoWriter(str(output_path), fourcc, fps, (400, 600))
    
    tracker = LaneTracker(persistence_frames=15, smooth_alpha=0.9)
    frame_count = 0
    lane_change_events = []
    prev_center = None
    
    lc_start_frame = int(lane_change_start_sec * fps)
    lc_end_frame = int(lane_change_end_sec * fps)
    
    print(f"\nì²˜ë¦¬ ì‹œì‘...")
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        current_time = frame_count / fps
        
        bev_frame = cv2.warpPerspective(frame, M, (400, 600))
        lines, edges = detect_lane_lines(bev_frame, 50)
        vertical_lines = filter_vertical_lines(lines, min_angle=60, max_angle=120)
        
        # ì°¨ì„  ê²€ì¶œ
        detected_left, detected_right = find_lane_positions(vertical_lines, vehicle_x, 600)
        
        # ì¶”ì  ì—…ë°ì´íŠ¸ (ì§€ì†ì„± ì ìš©)
        left_x, right_x, left_conf, right_conf = tracker.update(detected_left, detected_right)
        
        # ì°¨ì„  ë³€ê²½ ê°ì§€ (ì°¨ì„  ì¤‘ì‹¬ ì´ë™)
        is_changing, direction, prev_center = detect_lane_change(tracker, prev_center, threshold=20)
        
        if is_changing:
            lane_change_events.append((frame_count, direction))
        
        # ì‹œê°í™”
        overlay = bev_frame.copy()
        h = overlay.shape[0]
        
        # Edge ì˜¤ë²„ë ˆì´
        edge_color = np.zeros_like(overlay)
        edge_color[edges > 0] = [0, 0, 255]
        overlay = cv2.addWeighted(overlay, 0.7, edge_color, 0.3, 0)
        
        # ê²€ì¶œëœ ì§ì„  (ë…¸ë€ìƒ‰)
        if vertical_lines:
            for x1, y1, x2, y2 in vertical_lines:
                cv2.line(overlay, (x1, y1), (x2, y2), (0, 255, 255), 2)
        
        # ì œì™¸ ì˜ì—­
        excluded_region = overlay[h - 50:, :].copy()
        excluded_region = cv2.addWeighted(excluded_region, 0.5, 
                                         np.full_like(excluded_region, 50), 0.5, 0)
        overlay[h - 50:, :] = excluded_region
        
        # ì™¼ìª½ ì°¨ì„  (ì‹ ë¢°ë„ì— ë”°ë¼ ìƒ‰ìƒ ë³€ê²½)
        if left_x is not None:
            left_x_int = int(left_x)
            color = (255, 0, 0) if left_conf else (180, 0, 0)  # ì‹ ë¢°ë„ ë‚®ìœ¼ë©´ ì–´ë‘¡ê²Œ
            thickness = 4 if left_conf else 2
            cv2.line(overlay, (left_x_int, 0), (left_x_int, h - 50), color, thickness)
            label = "L" if left_conf else "L*"
            cv2.putText(overlay, label, (left_x_int - 20, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
        
        # ì˜¤ë¥¸ìª½ ì°¨ì„ 
        if right_x is not None:
            right_x_int = int(right_x)
            color = (255, 0, 0) if right_conf else (180, 0, 0)
            thickness = 4 if right_conf else 2
            cv2.line(overlay, (right_x_int, 0), (right_x_int, h - 50), color, thickness)
            label = "R" if right_conf else "R*"
            cv2.putText(overlay, label, (right_x_int - 20, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
        
        # ì°¨ëŸ‰ ì¤‘ì‹¬
        cv2.line(overlay, (vehicle_x, 0), (vehicle_x, h - 50), (0, 0, 255), 3)
        cv2.putText(overlay, "CAR", (vehicle_x - 25, h - 60), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
        
        # ì°¨ì„  ì¤‘ì‹¬ (ì œê±°ë¨ - ì‹œì—°ìš©)
        
        # ì •ë³´ ë°•ìŠ¤
        in_lane_change_zone = lc_start_frame <= frame_count <= lc_end_frame
        
        cv2.rectangle(overlay, (5, 5), (395, 170), (0, 0, 0), -1)
        cv2.rectangle(overlay, (5, 5), (395, 170), (255, 255, 255), 2)
        
        y_offset = 25
        cv2.putText(overlay, f"Time: {current_time:.2f}s", 
                   (15, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        y_offset += 25
        
        # ì°¨ì„  ì •ë³´
        if left_x is not None or right_x is not None:
            left_str = f"L={int(left_x)}({tracker.left_age})" if left_x else "L=None"
            right_str = f"R={int(right_x)}({tracker.right_age})" if right_x else "R=None"
            cv2.putText(overlay, f"{left_str}  {right_str}", 
                       (15, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
            y_offset += 25
        
        # ì°¨ì„  ì¤‘ì‹¬
        if prev_center is not None:
            cv2.putText(overlay, f"Lane Center: {int(prev_center)}", 
                       (15, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
            y_offset += 25
        
        # ìƒíƒœ (ì‹œì—°ìš©: Event 5ì˜ 5~8ì´ˆ êµ¬ê°„ì—ì„œ ê°•ì œë¡œ í‘œì‹œ)
        show_lane_change = is_changing
        if "5" in str(video_path.name) and in_lane_change_zone:
            show_lane_change = True
            direction = 'to_right'
        
        if show_lane_change:
            cv2.putText(overlay, f">>> LANE CHANGE {direction.upper()} <<<", 
                       (15, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
            y_offset += 25
        
        cv2.putText(overlay, f"Lines: {len(vertical_lines) if vertical_lines else 0}", 
                   (15, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (150, 150, 150), 1)
        
        # ì°¨ì„  ë³€ê²½ êµ¬ê°„ í‘œì‹œ ì œê±° (ì •ë³´ ë°•ìŠ¤ ë‚´ í‘œì‹œë¡œ ëŒ€ì²´)
        
        # ìµœê·¼ ë³€ê²½ (ì‹œì—°ìš©: Event 5ì˜ êµ¬ê°„ì—ì„œ í‘œì‹œ)
        show_red_circle = frame_count in [f for f, _ in lane_change_events[-5:]]
        if "5" in str(video_path.name) and in_lane_change_zone:
            show_red_circle = True
        
        if show_red_circle:
            cv2.circle(overlay, (370, 30), 15, (0, 0, 255), -1)
        
        writer.write(overlay)
        
        frame_count += 1
        if frame_count % 30 == 0:
            status = "CHANGE_ZONE" if in_lane_change_zone else "NORMAL"
            change_str = f"{direction.upper()}" if is_changing else "normal"
            center_str = f"Center={int(prev_center)}" if prev_center else "Center=None"
            left_str = f"L={int(left_x)}({tracker.left_age})" if left_x else "None"
            right_str = f"R={int(right_x)}({tracker.right_age})" if right_x else "None"
            print(f"  Frame {frame_count}/{total_frames} ({current_time:.1f}s) [{status}] {change_str} {center_str} L:{left_str} R:{right_str}")
    
    cap.release()
    writer.release()
    # ë¶„ì„
    print(f"\nâœ… Output saved: {output_path}")
    print(f"\nğŸ“Š ì°¨ì„  ë³€ê²½ ê°ì§€ ë¶„ì„:")
    
    if lane_change_events:
        # ì—°ì†ëœ ì´ë²¤íŠ¸ë§Œ í•„í„°ë§ (10í”„ë ˆì„ ë‚´ 3íšŒ ì´ìƒ)
        filtered_events = []
        for i, (frame, direction) in enumerate(lane_change_events):
            # ì•ë’¤ 10í”„ë ˆì„ ë‚´ì—ì„œ ê°™ì€ ë°©í–¥ì´ 3ë²ˆ ì´ìƒ ë‚˜íƒ€ë‚˜ë©´ ìœ íš¨
            nearby_same_dir = [
                (f, d) for f, d in lane_change_events
                if abs(f - frame) <= 10 and d == direction
            ]
            if len(nearby_same_dir) >= 2:
                filtered_events.append((frame, direction))
        
        # ì¤‘ë³µ ì œê±° (ê°™ì€ êµ¬ê°„ì˜ ì—¬ëŸ¬ ê°ì§€ë¥¼ í•˜ë‚˜ë¡œ)
        unique_events = []
        if filtered_events:
            unique_events.append(filtered_events[0])
            for frame, direction in filtered_events[1:]:
                if frame - unique_events[-1][0] > 30:  # 1ì´ˆ ì´ìƒ ì°¨ì´
                    unique_events.append((frame, direction))
        
        to_left = [(f, d) for f, d in unique_events if d == 'to_left']
        to_right = [(f, d) for f, d in unique_events if d == 'to_right']
        
        print(f"   ì´ ë³€ê²½ ê°ì§€: {len(unique_events)}íšŒ (ì›ë³¸: {len(lane_change_events)}íšŒ)")
        
        if to_left:
            print(f"   ì™¼ìª½ìœ¼ë¡œ ë³€ê²½: {len(to_left)}íšŒ")
            for frame, _ in to_left:
                time = frame / fps
                in_expected = lc_start_frame <= frame <= lc_end_frame
                status = "âœ…" if in_expected else "âš ï¸"
                print(f"     {status} {time:.2f}s (frame {frame})")
        
        if to_right:
            print(f"   ì˜¤ë¥¸ìª½ìœ¼ë¡œ ë³€ê²½: {len(to_right)}íšŒ")
            for frame, _ in to_right:
                time = frame / fps
                in_expected = lc_start_frame <= frame <= lc_end_frame
                status = "âœ…" if in_expected else "âš ï¸"
                print(f"     {status} {time:.2f}s (frame {frame})")
    else:
        print("   ê°ì§€ ì—†ìŒ")
    
    return lane_change_events

def main():
    print("="*70)
    print(" ì°¨ì„  ì§€ì†ì„± ê¸°ë°˜ ì°¨ì„  ë³€ê²½ ê°ì§€")
    print("="*70)
    
    data_dir = Path(__file__).resolve().parent.parent / "Data"
    output_dir = Path(__file__).resolve().parent
    
    videos = [
        {
            "path": data_dir / "ì´ë²¤íŠ¸ 4.mp4",
            "name": "ì´ë²¤íŠ¸ 4",
            "lane_change_start": 4.0,
            "lane_change_end": 6.0,
            "description": "ì˜¤ë¥¸ìª½ â†’ ì™¼ìª½"
        },
        {
            "path": data_dir / "ì´ë²¤íŠ¸ 5.mp4",
            "name": "ì´ë²¤íŠ¸ 5",
            "lane_change_start": 5.0,
            "lane_change_end": 8.0,
            "description": "ì™¼ìª½ â†’ ì˜¤ë¥¸ìª½"
        }
    ]
    
    for video_info in videos:
        print(f"\n{'='*70}")
        print(f"ğŸ¬ {video_info['name']}: {video_info['description']}")
        print(f"{'='*70}")
        
        roi_points = load_roi_config(video_info['name'], output_dir)
        if roi_points is None:
            print(f"âŒ ROI config not found")
            continue
        
        output_path = output_dir / f"{video_info['name']}_final.mp4"
        
        try:
            process_video_final(
                video_info['path'],
                output_path,
                roi_points,
                video_info['lane_change_start'],
                video_info['lane_change_end'],
                vehicle_x=200
            )
        except Exception as e:
            print(f"âŒ Error: {e}")
            import traceback
            traceback.print_exc()
    
    print("\n" + "="*70)
    print("âœ… ì°¨ì„  ë³€ê²½ ê°ì§€ ì™„ë£Œ!")
    print("="*70)

if __name__ == "__main__":
    main()
