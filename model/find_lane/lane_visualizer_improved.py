#!/usr/bin/env python3
"""
ì°¨ì„  ê²€ì¶œ ì‹œê°í™” ë„êµ¬ - ê°œì„ ëœ ë²„ì „
=================================
- í–¥ìƒëœ ì°¨ì„  ê²€ì¶œ (HSV + Edge Detection ê²°í•©)
- BEV ë³€í™˜ ì‹œê°í™” ê°œì„ 
- ë” ì •í™•í•œ ì°¨ì„  ê²½ê³„ ê²€ì¶œ
"""

from __future__ import annotations

import argparse
from pathlib import Path
from typing import Optional, Tuple

import cv2
import numpy as np


# BEV Transformation Parameters
H_MATRIX = np.array([
    [-3.97727273e-02, -3.24810606e-01, 1.00492424e02],
    [4.37257068e-16, -2.54829545e00, 7.89971591e02],
    [1.16574774e-18, -3.69318182e-03, 1.00000000e00],
])

# BEV ì´ë¯¸ì§€ì—ì„œ ì°¨ëŸ‰ ìœ„ì¹˜
MY_CAR_BEV_X = 105
MY_CAR_BEV_Y = 400

# Visualization colors (BGR format)
COLOR_LANE_MASK = (255, 255, 255)  # White for detected lanes
COLOR_LEFT_LANE = (255, 0, 0)      # Blue for left lane
COLOR_RIGHT_LANE = (255, 0, 0)     # Blue for right lane
COLOR_VEHICLE_CENTER = (0, 0, 255)  # Red for vehicle center
COLOR_ROI = (0, 255, 255)          # Yellow for ROI


class ImprovedLaneDetector:
    """ê°œì„ ëœ ì°¨ì„  ê²€ì¶œ í´ë˜ìŠ¤ - HSV + Edge Detection ê²°í•©"""
    
    def __init__(self, detection_method: str = "combined"):
        """
        Args:
            detection_method: 'hsv', 'edge', 'combined', 'adaptive'
        """
        self.method = detection_method
        
        # HSV ë²”ìœ„ (íŠœë‹ëœ íŒŒë¼ë¯¸í„°)
        self.lower_white = np.array([0, 0, 150])
        self.upper_white = np.array([180, 60, 255])
        self.lower_yellow = np.array([10, 60, 60])
        self.upper_yellow = np.array([40, 255, 255])
        
    def detect_lanes(self, frame: np.ndarray) -> np.ndarray:
        """ì°¨ì„  ë§ˆìŠ¤í¬ ê²€ì¶œ"""
        if self.method == "hsv":
            return self._detect_hsv(frame)
        elif self.method == "edge":
            return self._detect_edge(frame)
        elif self.method == "combined":
            return self._detect_combined(frame)
        elif self.method == "adaptive":
            return self._detect_adaptive(frame)
        else:
            return self._detect_combined(frame)
    
    def _detect_hsv(self, frame: np.ndarray) -> np.ndarray:
        """HSV ê¸°ë°˜ ê²€ì¶œ"""
        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
        
        white_mask = cv2.inRange(hsv, self.lower_white, self.upper_white)
        yellow_mask = cv2.inRange(hsv, self.lower_yellow, self.upper_yellow)
        
        combined = cv2.bitwise_or(white_mask, yellow_mask)
        
        # Morphological operations
        kernel = np.ones((3, 3), np.uint8)
        combined = cv2.morphologyEx(combined, cv2.MORPH_CLOSE, kernel)
        combined = cv2.morphologyEx(combined, cv2.MORPH_OPEN, kernel)
        
        return (combined > 127).astype(np.uint8)
    
    def _detect_edge(self, frame: np.ndarray) -> np.ndarray:
        """ì—£ì§€ ê¸°ë°˜ ê²€ì¶œ"""
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)
        edges = cv2.Canny(blurred, 50, 150)
        
        kernel = np.ones((3, 3), np.uint8)
        edges = cv2.dilate(edges, kernel, iterations=1)
        
        return (edges > 127).astype(np.uint8)
    
    def _detect_combined(self, frame: np.ndarray) -> np.ndarray:
        """HSV + Edge ê²°í•©"""
        hsv_mask = self._detect_hsv(frame)
        edge_mask = self._detect_edge(frame)
        
        combined = cv2.bitwise_or(hsv_mask * 255, edge_mask * 255)
        
        # Morphological operations
        kernel = np.ones((5, 5), np.uint8)
        combined = cv2.morphologyEx(combined, cv2.MORPH_CLOSE, kernel)
        
        return (combined > 127).astype(np.uint8)
    
    def _detect_adaptive(self, frame: np.ndarray) -> np.ndarray:
        """ì ì‘í˜• ì„ê³„ê°’"""
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        thresh = cv2.adaptiveThreshold(
            gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
            cv2.THRESH_BINARY, 11, 2
        )
        
        kernel = np.ones((3, 3), np.uint8)
        thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)
        
        return (thresh > 127).astype(np.uint8)


class BEVLaneAnalyzer:
    """BEV ë³€í™˜ ë° ì°¨ì„  ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(
        self, 
        lane_detector: ImprovedLaneDetector, 
        bev_size: Tuple[int, int] = (210, 600),
        show_debug: bool = False
    ):
        self.lane_detector = lane_detector
        self.bev_width, self.bev_height = bev_size
        self.show_debug = show_debug
        
    def apply_bev_transform(self, frame: np.ndarray) -> np.ndarray:
        """í”„ë ˆì„ì— BEV ë³€í™˜ ì ìš©"""
        bev = cv2.warpPerspective(
            frame, 
            H_MATRIX, 
            (self.bev_width, self.bev_height),
            flags=cv2.INTER_LINEAR
        )
        return bev
    
    def find_lane_boundaries(
        self, 
        lane_mask: np.ndarray, 
        vehicle_x: int,
        roi_y_range: Tuple[int, int] = None
    ) -> Tuple[Optional[int], Optional[int]]:
        """
        ì°¨ëŸ‰ ì¤‘ì‹¬ì„ ê¸°ì¤€ìœ¼ë¡œ ê°€ì¥ ê°€ê¹Œìš´ ì™¼ìª½/ì˜¤ë¥¸ìª½ ì°¨ì„  ê²½ê³„ ì°¾ê¸°
        
        Args:
            lane_mask: ì°¨ì„  ë§ˆìŠ¤í¬ (ì´ì§„ ì´ë¯¸ì§€)
            vehicle_x: ì°¨ëŸ‰ ì¤‘ì‹¬ x ì¢Œí‘œ
            roi_y_range: ROI y ë²”ìœ„ (start, end), Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
            
        Returns:
            (left_lane_x, right_lane_x) íŠœí”Œ. ì—†ìœ¼ë©´ None
        """
        if lane_mask.sum() == 0:
            return None, None
        
        # ê´€ì‹¬ ì˜ì—­(ROI) ì„¤ì •
        if roi_y_range is None:
            roi_y_start = max(0, MY_CAR_BEV_Y - 250)  # ë²”ìœ„ í™•ëŒ€
            roi_y_end = MY_CAR_BEV_Y
        else:
            roi_y_start, roi_y_end = roi_y_range
        
        roi = lane_mask[roi_y_start:roi_y_end, :]
        
        # ê° ì—´ì˜ ì°¨ì„  í”½ì…€ ê°œìˆ˜ë¥¼ ê°€ì¤‘ì¹˜ë¡œ ê³„ì‚° (ì•„ë˜ìª½ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜)
        weights = np.linspace(0.5, 1.0, roi.shape[0])[:, np.newaxis]
        weighted_roi = roi.astype(np.float32) * weights
        column_sums = weighted_roi.sum(axis=0)
        
        # ì°¨ì„ ì´ ìˆëŠ” ì—´ ì°¾ê¸°
        lane_threshold = 3  # ì„ê³„ê°’ ë‚®ì¶¤
        lane_columns = np.where(column_sums > lane_threshold)[0]
        
        if len(lane_columns) == 0:
            return None, None
        
        # ì—°ì†ëœ ì°¨ì„  ì˜ì—­ì„ ì°¾ê¸° ìœ„í•´ clustering
        lane_groups = []
        current_group = [lane_columns[0]]
        
        for i in range(1, len(lane_columns)):
            if lane_columns[i] - lane_columns[i-1] <= 8:  # í´ëŸ¬ìŠ¤í„°ë§ gap ì¦ê°€
                current_group.append(lane_columns[i])
            else:
                if len(current_group) >= 2:  # ìµœì†Œ 2í”½ì…€ë¡œ ì™„í™”
                    lane_groups.append(current_group)
                current_group = [lane_columns[i]]
        
        if len(current_group) >= 2:
            lane_groups.append(current_group)
        
        if len(lane_groups) == 0:
            return None, None
        
        # ê° ê·¸ë£¹ì˜ ê°€ì¤‘ ì¤‘ì‹¬ ê³„ì‚° (í”½ì…€ ê°•ë„ ê³ ë ¤)
        lane_centers = []
        for group in lane_groups:
            weights_for_group = column_sums[group]
            if weights_for_group.sum() > 0:
                weighted_center = np.average(group, weights=weights_for_group)
                lane_centers.append(int(weighted_center))
        
        if len(lane_centers) == 0:
            return None, None
        
        # ì°¨ëŸ‰ ì¤‘ì‹¬ ê¸°ì¤€ìœ¼ë¡œ ì™¼ìª½/ì˜¤ë¥¸ìª½ ì°¨ì„  ì°¾ê¸°
        left_lanes = [x for x in lane_centers if x < vehicle_x]
        right_lanes = [x for x in lane_centers if x > vehicle_x]
        
        # ê°€ì¥ ê°€ê¹Œìš´ ì™¼ìª½/ì˜¤ë¥¸ìª½ ì°¨ì„ 
        left_lane_x = max(left_lanes) if len(left_lanes) > 0 else None
        right_lane_x = min(right_lanes) if len(right_lanes) > 0 else None
        
        return left_lane_x, right_lane_x
    
    def calculate_lane_metrics(
        self, 
        left_lane_x: Optional[int], 
        right_lane_x: Optional[int], 
        vehicle_x: int,
        pixels_per_meter: float = 20.0
    ) -> Tuple[float, float, bool, bool]:
        """ì°¨ì„  ê±°ë¦¬ ë° ì´íƒˆë¥  ê³„ì‚°"""
        lane_detected = False
        lane_normal = False
        lane_width_m = 0.0
        departure_rate = 0.0
        
        if left_lane_x is not None and right_lane_x is not None:
            lane_detected = True
            
            lane_width_px = right_lane_x - left_lane_x
            lane_width_m = lane_width_px / pixels_per_meter
            
            lane_center_x = (left_lane_x + right_lane_x) / 2
            offset_px = vehicle_x - lane_center_x
            
            if lane_width_px > 0:
                departure_rate = offset_px / lane_width_px
            
            # ì •ìƒ ë²”ìœ„ íŒë‹¨ (Â±35%ë¡œ ì™„í™”)
            lane_normal = abs(departure_rate) < 0.35
        
        elif left_lane_x is not None or right_lane_x is not None:
            lane_detected = True
            lane_normal = False
            
            if left_lane_x is not None:
                offset_px = vehicle_x - left_lane_x
                departure_rate = offset_px / 60.0
            else:
                offset_px = vehicle_x - right_lane_x
                departure_rate = offset_px / 60.0
        
        return lane_width_m, departure_rate, lane_detected, lane_normal
    
    def process_frame(
        self, 
        frame: np.ndarray
    ) -> Tuple[np.ndarray, dict]:
        """í”„ë ˆì„ ì²˜ë¦¬ ë° ì‹œê°í™” ì˜¤ë²„ë ˆì´ ìƒì„±"""
        # 1. BEV ë³€í™˜
        bev_frame = self.apply_bev_transform(frame)
        
        # 2. ì°¨ì„  ê²€ì¶œ
        lane_mask = self.lane_detector.detect_lanes(bev_frame)
        
        # 3. ì°¨ì„  ê²½ê³„ ì°¾ê¸°
        left_lane_x, right_lane_x = self.find_lane_boundaries(lane_mask, MY_CAR_BEV_X)
        
        # 4. ë©”íŠ¸ë¦­ ê³„ì‚°
        lane_width_m, departure_rate, lane_detected, lane_normal = self.calculate_lane_metrics(
            left_lane_x, right_lane_x, MY_CAR_BEV_X
        )
        
        # 5. ì‹œê°í™”
        overlay = self._create_visualization(
            bev_frame, lane_mask, left_lane_x, right_lane_x
        )
        
        # 6. í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´
        self._add_text_overlay(
            overlay, lane_width_m, departure_rate, lane_detected, lane_normal
        )
        
        metrics = {
            'lane_width_m': lane_width_m,
            'departure_rate': departure_rate,
            'lane_detected': lane_detected,
            'lane_normal': lane_normal,
            'left_lane_x': left_lane_x,
            'right_lane_x': right_lane_x,
        }
        
        return overlay, metrics
    
    def _create_visualization(
        self, 
        bev_frame: np.ndarray, 
        lane_mask: np.ndarray,
        left_lane_x: Optional[int],
        right_lane_x: Optional[int]
    ) -> np.ndarray:
        """ì‹œê°í™” ì˜¤ë²„ë ˆì´ ìƒì„±"""
        overlay = bev_frame.copy()
        
        # ROI ì˜ì—­ í‘œì‹œ (ë””ë²„ê·¸ìš©)
        if self.show_debug:
            roi_y_start = max(0, MY_CAR_BEV_Y - 250)
            cv2.rectangle(
                overlay,
                (0, roi_y_start),
                (overlay.shape[1] - 1, MY_CAR_BEV_Y),
                COLOR_ROI,
                2
            )
        
        # ì°¨ì„  ë§ˆìŠ¤í¬ ì˜¤ë²„ë ˆì´ (ë°˜íˆ¬ëª…)
        lane_mask_color = np.zeros_like(overlay)
        lane_mask_color[lane_mask > 0] = COLOR_LANE_MASK
        overlay = cv2.addWeighted(overlay, 0.6, lane_mask_color, 0.4, 0)
        
        # ì™¼ìª½ ì°¨ì„  ê²½ê³„ì„ 
        if left_lane_x is not None:
            cv2.line(
                overlay,
                (left_lane_x, MY_CAR_BEV_Y - 250),
                (left_lane_x, MY_CAR_BEV_Y),
                COLOR_LEFT_LANE,
                4
            )
            cv2.putText(
                overlay, "L", 
                (left_lane_x - 15, MY_CAR_BEV_Y - 260),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, COLOR_LEFT_LANE, 2
            )
        
        # ì˜¤ë¥¸ìª½ ì°¨ì„  ê²½ê³„ì„ 
        if right_lane_x is not None:
            cv2.line(
                overlay,
                (right_lane_x, MY_CAR_BEV_Y - 250),
                (right_lane_x, MY_CAR_BEV_Y),
                COLOR_RIGHT_LANE,
                4
            )
            cv2.putText(
                overlay, "R", 
                (right_lane_x - 15, MY_CAR_BEV_Y - 260),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, COLOR_RIGHT_LANE, 2
            )
        
        # ì°¨ì„  ì¤‘ì‹¬ì„  (ë‘ ì°¨ì„ ì´ ëª¨ë‘ ê²€ì¶œëœ ê²½ìš°)
        if left_lane_x is not None and right_lane_x is not None:
            lane_center = int((left_lane_x + right_lane_x) / 2)
            cv2.line(
                overlay,
                (lane_center, MY_CAR_BEV_Y - 250),
                (lane_center, MY_CAR_BEV_Y),
                (0, 255, 0),  # Green
                2,
                cv2.LINE_AA
            )
        
        # ì°¨ëŸ‰ ì¤‘ì‹¬ (ë¹¨ê°„ìƒ‰)
        cv2.circle(overlay, (MY_CAR_BEV_X, MY_CAR_BEV_Y), 10, COLOR_VEHICLE_CENTER, -1)
        cv2.circle(overlay, (MY_CAR_BEV_X, MY_CAR_BEV_Y), 12, (255, 255, 255), 2)
        
        # ì°¨ëŸ‰ ë ˆì´ë¸”
        cv2.putText(
            overlay, "CAR", 
            (MY_CAR_BEV_X - 20, MY_CAR_BEV_Y + 30),
            cv2.FONT_HERSHEY_SIMPLEX, 0.6, COLOR_VEHICLE_CENTER, 2
        )
        
        # ì°¨ëŸ‰ì—ì„œ ì°¨ì„ ê¹Œì§€ ì—°ê²°ì„ 
        if left_lane_x is not None:
            cv2.line(
                overlay,
                (MY_CAR_BEV_X, MY_CAR_BEV_Y),
                (left_lane_x, MY_CAR_BEV_Y),
                (200, 200, 200),
                1,
                cv2.LINE_AA
            )
        if right_lane_x is not None:
            cv2.line(
                overlay,
                (MY_CAR_BEV_X, MY_CAR_BEV_Y),
                (right_lane_x, MY_CAR_BEV_Y),
                (200, 200, 200),
                1,
                cv2.LINE_AA
            )
        
        return overlay
    
    def _add_text_overlay(
        self,
        frame: np.ndarray,
        lane_width_m: float,
        departure_rate: float,
        lane_detected: bool,
        lane_normal: bool
    ) -> None:
        """í…ìŠ¤íŠ¸ ì •ë³´ ì˜¤ë²„ë ˆì´"""
        y_offset = 30
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.7
        thickness = 2
        
        # ë°°ê²½ ë°•ìŠ¤
        cv2.rectangle(frame, (5, 5), (frame.shape[1] - 5, 145), (0, 0, 0), -1)
        cv2.rectangle(frame, (5, 5), (frame.shape[1] - 5, 145), (255, 255, 255), 2)
        
        # Lane Detection Status
        status_text = "DETECTED" if lane_detected else "NOT DETECTED"
        status_color = (0, 255, 0) if lane_detected else (0, 0, 255)
        cv2.putText(frame, f"Lane: {status_text}", (15, y_offset), font, font_scale, status_color, thickness)
        y_offset += 30
        
        if lane_detected:
            # Lane Normal Status
            normal_text = "NORMAL" if lane_normal else "ABNORMAL"
            normal_color = (0, 255, 0) if lane_normal else (0, 165, 255)
            cv2.putText(frame, f"Status: {normal_text}", (15, y_offset), font, font_scale, normal_color, thickness)
            y_offset += 30
            
            # Lane Width
            if lane_width_m > 0:
                width_text = f"Width: {lane_width_m:.2f}m"
                cv2.putText(frame, width_text, (15, y_offset), font, font_scale, (255, 255, 255), thickness)
                y_offset += 30
            
            # Departure Rate
            departure_text = f"Depart: {departure_rate:+.1%}"
            departure_color = (0, 255, 0) if abs(departure_rate) < 0.35 else (0, 165, 255)
            cv2.putText(frame, departure_text, (15, y_offset), font, font_scale, departure_color, thickness)


def process_video(
    video_path: Path,
    output_path: Path,
    detection_method: str = "combined",
    show_debug: bool = False
) -> None:
    """ë¹„ë””ì˜¤ ì²˜ë¦¬ ë° ì˜¤ë²„ë ˆì´ ìƒì„±"""
    print(f"ğŸ¥ Processing: {video_path.name}")
    print(f"   Method: {detection_method}")
    
    # Initialize
    lane_detector = ImprovedLaneDetector(detection_method)
    analyzer = BEVLaneAnalyzer(lane_detector, show_debug=show_debug)
    
    # Open video
    cap = cv2.VideoCapture(str(video_path))
    if not cap.isOpened():
        raise RuntimeError(f"Cannot open video: {video_path}")
    
    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    # Create output writer
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    writer = cv2.VideoWriter(str(output_path), fourcc, fps, (210, 600))
    
    frame_count = 0
    detected_count = 0
    normal_count = 0
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        # Process frame
        overlay, metrics = analyzer.process_frame(frame)
        
        # Write output
        writer.write(overlay)
        
        if metrics['lane_detected']:
            detected_count += 1
        if metrics['lane_normal']:
            normal_count += 1
        
        frame_count += 1
        if frame_count % 30 == 0:
            print(f"  Frame {frame_count}/{total_frames} - "
                  f"Detected: {metrics['lane_detected']}, "
                  f"Normal: {metrics['lane_normal']}, "
                  f"Depart: {metrics['departure_rate']:+.1%}")
    
    cap.release()
    writer.release()
    
    print(f"âœ… Output saved: {output_path}")
    print(f"   Detection rate: {detected_count}/{frame_count} ({100*detected_count/max(1,frame_count):.1f}%)")
    print(f"   Normal rate: {normal_count}/{frame_count} ({100*normal_count/max(1,frame_count):.1f}%)")


def main():
    parser = argparse.ArgumentParser(description="Improved Lane Detection Visualization")
    parser.add_argument(
        "--videos",
        nargs="+",
        required=True,
        help="Input video paths"
    )
    parser.add_argument(
        "--output-dir",
        type=Path,
        default=Path(__file__).resolve().parent,
        help="Output directory"
    )
    parser.add_argument(
        "--method",
        type=str,
        choices=["hsv", "edge", "combined", "adaptive"],
        default="combined",
        help="Detection method"
    )
    parser.add_argument(
        "--debug",
        action="store_true",
        help="Show debug ROI"
    )
    
    args = parser.parse_args()
    
    args.output_dir.mkdir(parents=True, exist_ok=True)
    
    for video_path in args.videos:
        video_path = Path(video_path)
        if not video_path.exists():
            print(f"âš ï¸  Video not found: {video_path}")
            continue
        
        output_path = args.output_dir / f"{video_path.stem}_improved.mp4"
        
        try:
            process_video(video_path, output_path, args.method, args.debug)
        except Exception as e:
            print(f"âŒ Error processing {video_path.name}: {e}")
            import traceback
            traceback.print_exc()


if __name__ == "__main__":
    main()
