#!/usr/bin/env python3
"""
ì°¨ì„  ê²€ì¶œ ë””ë²„ê·¸ ì˜ìƒ ìƒì„±ê¸°
- ì›ë³¸, BEV, ì°¨ì„  ë§ˆìŠ¤í¬, ìµœì¢… ê²°ê³¼ë¥¼ í•¨ê»˜ í‘œì‹œ
- ì°¨ì„  ì¤‘ì‹¬ ìœ„ì¹˜ ë³€í™” ê·¸ë˜í”„
"""
import cv2
import numpy as np
from pathlib import Path
import json
import matplotlib.pyplot as plt
from matplotlib.backends.backend_agg import FigureCanvasAgg

def load_roi_config(video_name: str, output_dir: Path):
    config_path = output_dir / f"{video_name}_roi_config.json"
    if not config_path.exists():
        return None
    with open(config_path, 'r') as f:
        config = json.load(f)
    return np.float32(config['roi_points'])

def detect_lanes_improved(bev_frame, exclude_bottom_height=100):
    h, w = bev_frame.shape[:2]
    
    hsv = cv2.cvtColor(bev_frame, cv2.COLOR_BGR2HSV)
    
    # í°ìƒ‰
    lower_white = np.array([0, 0, 150])
    upper_white = np.array([180, 60, 255])
    white_mask = cv2.inRange(hsv, lower_white, upper_white)
    
    # ë…¸ë€ìƒ‰
    lower_yellow = np.array([10, 60, 60])
    upper_yellow = np.array([40, 255, 255])
    yellow_mask = cv2.inRange(hsv, lower_yellow, upper_yellow)
    
    # Edge
    gray = cv2.cvtColor(bev_frame, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    edges = cv2.Canny(blurred, 50, 150)
    
    # ê²°í•©
    hsv_combined = cv2.bitwise_or(white_mask, yellow_mask)
    combined = cv2.bitwise_or(hsv_combined, edges)
    
    # Morphological
    kernel = np.ones((5, 5), np.uint8)
    combined = cv2.morphologyEx(combined, cv2.MORPH_CLOSE, kernel)
    
    # í•˜ë‹¨ ë§ˆìŠ¤í‚¹
    mask = np.ones_like(combined)
    mask[h - exclude_bottom_height:, :] = 0
    combined = cv2.bitwise_and(combined, mask)
    
    return (combined > 127).astype(np.uint8), white_mask, yellow_mask, edges

def find_lane_boundaries(lane_mask):
    if lane_mask.sum() == 0:
        return None, None, None
    
    height = lane_mask.shape[0]
    roi_bottom = int(height * 0.8)
    roi_top = int(height * 0.3)
    roi = lane_mask[roi_top:roi_bottom, :]
    
    weights = np.linspace(0.5, 1.0, roi.shape[0])[:, np.newaxis]
    weighted_roi = roi.astype(np.float32) * weights
    column_sums = weighted_roi.sum(axis=0)
    
    lane_threshold = 3
    lane_columns = np.where(column_sums > lane_threshold)[0]
    
    if len(lane_columns) == 0:
        return None, None, None
    
    # í´ëŸ¬ìŠ¤í„°ë§
    lane_groups = []
    current_group = [lane_columns[0]]
    
    for i in range(1, len(lane_columns)):
        if lane_columns[i] - lane_columns[i-1] <= 8:
            current_group.append(lane_columns[i])
        else:
            if len(current_group) >= 2:
                lane_groups.append(current_group)
            current_group = [lane_columns[i]]
    
    if len(current_group) >= 2:
        lane_groups.append(current_group)
    
    if len(lane_groups) == 0:
        return None, None, None
    
    lane_centers = []
    for group in lane_groups:
        weights_for_group = column_sums[group]
        if weights_for_group.sum() > 0:
            weighted_center = np.average(group, weights=weights_for_group)
            lane_centers.append(int(weighted_center))
    
    if len(lane_centers) == 0:
        return None, None, None
    
    left_lane_x = min(lane_centers) if len(lane_centers) > 0 else None
    right_lane_x = max(lane_centers) if len(lane_centers) > 1 else None
    
    if left_lane_x is not None and right_lane_x is not None:
        lane_center_x = int((left_lane_x + right_lane_x) / 2)
    else:
        lane_center_x = None
    
    return left_lane_x, right_lane_x, lane_center_x

def create_debug_composite(original, bev, white_mask, yellow_mask, edges, lane_mask, 
                          left_x, right_x, center_x, current_time, center_history):
    """4ê°œ íŒ¨ë„ + ê·¸ë˜í”„ë¥¼ í•©ì¹œ ë””ë²„ê·¸ ì˜ìƒ"""
    # ê° ì´ë¯¸ì§€ë¥¼ ì‘ì€ í¬ê¸°ë¡œ ì¡°ì •
    h, w = 300, 400
    
    # 1. ì›ë³¸ (BEV)
    panel1 = cv2.resize(bev, (w, h))
    cv2.putText(panel1, "1. BEV Transform", (10, 30), 
               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
    
    # 2. í°ìƒ‰ ì°¨ì„  ë§ˆìŠ¤í¬
    panel2 = cv2.cvtColor(white_mask, cv2.COLOR_GRAY2BGR)
    panel2 = cv2.resize(panel2, (w, h))
    cv2.putText(panel2, "2. White Lanes", (10, 30), 
               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
    
    # 3. ë…¸ë€ìƒ‰ ì°¨ì„  ë§ˆìŠ¤í¬
    panel3 = cv2.cvtColor(yellow_mask, cv2.COLOR_GRAY2BGR)
    panel3 = cv2.resize(panel3, (w, h))
    cv2.putText(panel3, "3. Yellow Lanes", (10, 30), 
               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
    
    # 4. Edge ê²€ì¶œ
    panel4 = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)
    panel4 = cv2.resize(panel4, (w, h))
    cv2.putText(panel4, "4. Edge Detection", (10, 30), 
               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
    
    # 5. ìµœì¢… ë§ˆìŠ¤í¬
    panel5 = cv2.cvtColor(lane_mask * 255, cv2.COLOR_GRAY2BGR)
    panel5 = cv2.resize(panel5, (w, h))
    cv2.putText(panel5, "5. Combined Mask", (10, 30), 
               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
    
    # 6. ì°¨ì„  ê²€ì¶œ ê²°ê³¼
    panel6 = cv2.resize(bev, (w, h))
    if left_x is not None:
        left_x_scaled = int(left_x * w / 400)
        cv2.line(panel6, (left_x_scaled, 0), (left_x_scaled, h), (255, 0, 0), 3)
    if right_x is not None:
        right_x_scaled = int(right_x * w / 400)
        cv2.line(panel6, (right_x_scaled, 0), (right_x_scaled, h), (255, 0, 0), 3)
    if center_x is not None:
        center_x_scaled = int(center_x * w / 400)
        cv2.line(panel6, (center_x_scaled, 0), (center_x_scaled, h), (0, 255, 0), 3)
    cv2.putText(panel6, "6. Lane Detection", (10, 30), 
               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
    
    # ì™¼ìª½: 4ê°œ íŒ¨ë„ (2x2)
    top_row = np.hstack([panel1, panel2])
    mid_row = np.hstack([panel3, panel4])
    bottom_row = np.hstack([panel5, panel6])
    left_side = np.vstack([top_row, mid_row, bottom_row])
    
    # ì˜¤ë¥¸ìª½: ê·¸ë˜í”„ (ì°¨ì„  ì¤‘ì‹¬ ë³€í™”)
    fig = plt.figure(figsize=(8, 9))
    ax = fig.add_subplot(111)
    
    if len(center_history) > 0:
        times, centers = zip(*center_history)
        ax.plot(times, centers, 'g-', linewidth=2, label='Lane Center')
        ax.axhline(y=200, color='r', linestyle='--', alpha=0.5, label='Target Center')
        ax.scatter([current_time], [center_x if center_x else 200], 
                  c='red', s=100, zorder=5, label='Current')
    
    ax.set_xlabel('Time (s)', fontsize=12)
    ax.set_ylabel('Lane Center Position (px)', fontsize=12)
    ax.set_title('Lane Center Tracking', fontsize=14, fontweight='bold')
    ax.grid(True, alpha=0.3)
    ax.legend()
    ax.set_ylim([0, 400])
    
    # ê·¸ë˜í”„ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
    canvas = FigureCanvasAgg(fig)
    canvas.draw()
    buf = canvas.buffer_rgba()
    graph_image = np.asarray(buf)
    graph_image = cv2.cvtColor(graph_image, cv2.COLOR_RGBA2BGR)
    plt.close(fig)
    
    # ê·¸ë˜í”„ë¥¼ ì™¼ìª½ê³¼ ê°™ì€ ë†’ì´ë¡œ ì¡°ì •
    graph_image = cv2.resize(graph_image, (800, h * 3))
    
    # ìµœì¢… í•©ì„±
    composite = np.hstack([left_side, graph_image])
    
    # ìƒë‹¨ì— ì •ë³´ ì¶”ê°€
    info = np.zeros((80, composite.shape[1], 3), dtype=np.uint8)
    cv2.putText(info, f"Time: {current_time:.2f}s", (20, 30),
               cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
    
    if left_x is not None and right_x is not None:
        lane_width = right_x - left_x
        cv2.putText(info, f"Lane Width: {lane_width}px", (20, 60),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 1)
    
    if center_x is not None:
        cv2.putText(info, f"Center: {center_x}px", (300, 60),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 1)
    
    final = np.vstack([info, composite])
    
    return final

def process_debug_video(video_path: Path, output_path: Path, src_points: np.ndarray):
    print(f"\nğŸ¥ Creating debug video: {video_path.name}")
    
    dst_points = np.float32([[0, 0], [400, 0], [400, 600], [0, 600]])
    M = cv2.getPerspectiveTransform(src_points, dst_points)
    
    cap = cv2.VideoCapture(str(video_path))
    if not cap.isOpened():
        raise RuntimeError(f"Cannot open video: {video_path}")
    
    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    # ì²« í”„ë ˆì„ìœ¼ë¡œ ì¶œë ¥ í¬ê¸° ê²°ì •
    ret, first_frame = cap.read()
    if not ret:
        raise RuntimeError("Cannot read first frame")
    
    bev_frame = cv2.warpPerspective(first_frame, M, (400, 600))
    lane_mask, white, yellow, edges = detect_lanes_improved(bev_frame, 100)
    left_x, right_x, center_x = find_lane_boundaries(lane_mask)
    debug_frame = create_debug_composite(first_frame, bev_frame, white, yellow, edges,
                                         lane_mask, left_x, right_x, center_x, 0, [])
    
    out_height, out_width = debug_frame.shape[:2]
    
    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)  # ì²˜ìŒìœ¼ë¡œ ë˜ëŒë¦¼
    
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    writer = cv2.VideoWriter(str(output_path), fourcc, fps, (out_width, out_height))
    
    frame_count = 0
    center_history = []
    
    print(f"Output size: {out_width}x{out_height}")
    print(f"Processing {total_frames} frames...")
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        current_time = frame_count / fps
        
        # BEV ë³€í™˜
        bev_frame = cv2.warpPerspective(frame, M, (400, 600))
        
        # ì°¨ì„  ê²€ì¶œ
        lane_mask, white, yellow, edges = detect_lanes_improved(bev_frame, 100)
        left_x, right_x, center_x = find_lane_boundaries(lane_mask)
        
        # ì´ë ¥ ê¸°ë¡
        if center_x is not None:
            center_history.append((current_time, center_x))
            # ìµœê·¼ 150í”„ë ˆì„ë§Œ ìœ ì§€ (5ì´ˆ)
            if len(center_history) > 150:
                center_history = center_history[-150:]
        
        # ë””ë²„ê·¸ í•©ì„± ì´ë¯¸ì§€ ìƒì„±
        debug_frame = create_debug_composite(
            frame, bev_frame, white, yellow, edges, lane_mask,
            left_x, right_x, center_x, current_time, center_history
        )
        
        writer.write(debug_frame)
        
        frame_count += 1
        if frame_count % 30 == 0:
            print(f"  Frame {frame_count}/{total_frames} ({current_time:.1f}s)")
    
    cap.release()
    writer.release()
    
    print(f"âœ… Debug video saved: {output_path}")

def main():
    print("="*70)
    print(" ì°¨ì„  ê²€ì¶œ ë””ë²„ê·¸ ì˜ìƒ ìƒì„±")
    print("="*70)
    
    data_dir = Path(__file__).resolve().parent.parent / "Data"
    output_dir = Path(__file__).resolve().parent
    
    videos = [
        {"path": data_dir / "ì´ë²¤íŠ¸ 4.mp4", "name": "ì´ë²¤íŠ¸ 4"},
        {"path": data_dir / "ì´ë²¤íŠ¸ 5.mp4", "name": "ì´ë²¤íŠ¸ 5"}
    ]
    
    for video_info in videos:
        print(f"\n{'='*70}")
        print(f"ğŸ¬ {video_info['name']}")
        print(f"{'='*70}")
        
        roi_points = load_roi_config(video_info['name'], output_dir)
        if roi_points is None:
            print(f"âŒ ROI config not found")
            continue
        
        output_path = output_dir / f"{video_info['name']}_debug.mp4"
        
        try:
            process_debug_video(video_info['path'], output_path, roi_points)
        except Exception as e:
            print(f"âŒ Error: {e}")
            import traceback
            traceback.print_exc()
    
    print("\n" + "="*70)
    print("âœ… ë””ë²„ê·¸ ì˜ìƒ ìƒì„± ì™„ë£Œ!")
    print("="*70)
    print("\nìƒì„±ëœ íŒŒì¼:")
    print("  - ì´ë²¤íŠ¸ 4_debug.mp4")
    print("  - ì´ë²¤íŠ¸ 5_debug.mp4")
    print("\nê° ì˜ìƒì€ 6ê°œ íŒ¨ë„ + ì°¨ì„  ì¤‘ì‹¬ ê·¸ë˜í”„ë¥¼ í¬í•¨í•©ë‹ˆë‹¤:")
    print("  1. BEV Transform")
    print("  2. White Lanes")
    print("  3. Yellow Lanes")
    print("  4. Edge Detection")
    print("  5. Combined Mask")
    print("  6. Lane Detection Result")
    print("  + Lane Center Tracking Graph")

if __name__ == "__main__":
    main()
