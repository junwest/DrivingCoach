#!/usr/bin/env python3
"""
ì¸í„°ë™í‹°ë¸Œ ë¹„ë””ì˜¤ ë””ë²„ê±° - í”„ë ˆì„ ì¶”ì¶œ ë° í™•ì¸
"""
import cv2
import numpy as np
from pathlib import Path
import json

def load_roi_config(video_name: str, output_dir: Path):
    """ROI ì„¤ì • ë¡œë“œ"""
    config_path = output_dir / f"{video_name}_roi_config.json"
    if not config_path.exists():
        return None
    
    with open(config_path, 'r') as f:
        config = json.load(f)
    
    return np.float32(config['roi_points'])

def extract_debug_frames():
    """ë””ë²„ê·¸ìš© í”„ë ˆì„ ì¶”ì¶œ"""
    data_dir = Path(__file__).resolve().parent.parent / "Data"
    output_dir = Path(__file__).resolve().parent
    
    videos = [
        {
            "path": data_dir / "ì´ë²¤íŠ¸ 4.mp4",
            "name": "ì´ë²¤íŠ¸ 4",
            "frame_sec": 5.0  # ì°¨ì„  ë³€ê²½ ì¤‘ê°„
        },
        {
            "path": data_dir / "ì´ë²¤íŠ¸ 5.mp4",
            "name": "ì´ë²¤íŠ¸ 5",
            "frame_sec": 6.5  # ì°¨ì„  ë³€ê²½ ì¤‘ê°„
        }
    ]
    
    for video_info in videos:
        print(f"\n{'='*60}")
        print(f"ğŸ¬ {video_info['name']}")
        print(f"{'='*60}")
        
        # ROI ë¡œë“œ
        roi_points = load_roi_config(video_info['name'], output_dir)
        if roi_points is None:
            print(f"âŒ ROI config not found for {video_info['name']}")
            continue
        
        print(f"ROI Points: {roi_points.tolist()}")
        
        # ë¹„ë””ì˜¤ ë¡œë“œ
        cap = cv2.VideoCapture(str(video_info['path']))
        fps = cap.get(cv2.CAP_PROP_FPS) or 30.0
        
        # íŠ¹ì • í”„ë ˆì„ìœ¼ë¡œ ì´ë™
        frame_num = int(video_info['frame_sec'] * fps)
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)
        ret, frame = cap.read()
        cap.release()
        
        if not ret:
            print(f"âŒ Failed to read frame")
            continue
        
        # ì›ë³¸ í”„ë ˆì„ ì €ì¥
        original_path = output_dir / f"{video_info['name']}_original.jpg"
        cv2.imwrite(str(original_path), frame)
        print(f"âœ… Original frame saved: {original_path}")
        
        # ROI í‘œì‹œí•œ í”„ë ˆì„ ì €ì¥
        roi_frame = frame.copy()
        for i in range(4):
            pt1 = tuple(roi_points[i].astype(int))
            pt2 = tuple(roi_points[(i + 1) % 4].astype(int))
            cv2.line(roi_frame, pt1, pt2, (0, 255, 0), 3)
            cv2.circle(roi_frame, pt1, 8, (0, 0, 255), -1)
            cv2.putText(roi_frame, str(i+1), 
                       tuple((roi_points[i] + [15, -15]).astype(int)),
                       cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 3)
        
        roi_vis_path = output_dir / f"{video_info['name']}_roi_visual.jpg"
        cv2.imwrite(str(roi_vis_path), roi_frame)
        print(f"âœ… ROI visualization saved: {roi_vis_path}")
        
        # BEV ë³€í™˜
        dst_points = np.float32([
            [0, 0],
            [400, 0],
            [400, 600],
            [0, 600]
        ])
        
        M = cv2.getPerspectiveTransform(roi_points, dst_points)
        bev_frame = cv2.warpPerspective(frame, M, (400, 600))
        
        bev_path = output_dir / f"{video_info['name']}_bev.jpg"
        cv2.imwrite(str(bev_path), bev_frame)
        print(f"âœ… BEV frame saved: {bev_path}")
        
        # ì°¨ì„  ê²€ì¶œ
        hsv = cv2.cvtColor(bev_frame, cv2.COLOR_BGR2HSV)
        
        # í°ìƒ‰
        lower_white = np.array([0, 0, 150])
        upper_white = np.array([180, 60, 255])
        white_mask = cv2.inRange(hsv, lower_white, upper_white)
        
        # ë…¸ë€ìƒ‰
        lower_yellow = np.array([10, 60, 60])
        upper_yellow = np.array([40, 255, 255])
        yellow_mask = cv2.inRange(hsv, lower_yellow, upper_yellow)
        
        # Edge
        gray = cv2.cvtColor(bev_frame, cv2.COLOR_BGR2GRAY)
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)
        edges = cv2.Canny(blurred, 50, 150)
        
        # ê²°í•©
        hsv_combined = cv2.bitwise_or(white_mask, yellow_mask)
        combined = cv2.bitwise_or(hsv_combined, edges)
        
        # Morphological
        kernel = np.ones((5, 5), np.uint8)
        combined = cv2.morphologyEx(combined, cv2.MORPH_CLOSE, kernel)
        
        # ë§ˆìŠ¤í¬ ì €ì¥
        mask_path = output_dir / f"{video_info['name']}_lane_mask.jpg"
        cv2.imwrite(str(mask_path), combined)
        print(f"âœ… Lane mask saved: {mask_path}")
        
        # ì˜¤ë²„ë ˆì´
        overlay = bev_frame.copy()
        overlay[combined > 127] = [255, 255, 255]
        
        overlay_path = output_dir / f"{video_info['name']}_overlay.jpg"
        cv2.imwrite(str(overlay_path), overlay)
        print(f"âœ… Overlay saved: {overlay_path}")
        
        # í†µê³„
        total_pixels = combined.shape[0] * combined.shape[1]
        lane_pixels = np.sum(combined > 127)
        percentage = 100 * lane_pixels / total_pixels
        
        print(f"\nğŸ“Š Statistics:")
        print(f"   Frame size: {frame.shape[1]}x{frame.shape[0]}")
        print(f"   BEV size: {bev_frame.shape[1]}x{bev_frame.shape[0]}")
        print(f"   Lane pixels: {lane_pixels}/{total_pixels} ({percentage:.1f}%)")

    print("\n" + "="*60)
    print("âœ… ë””ë²„ê·¸ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ!")
    print("="*60)
    print("\ní™•ì¸í•  ì´ë¯¸ì§€:")
    print("  *_original.jpg    - ì›ë³¸ í”„ë ˆì„")
    print("  *_roi_visual.jpg  - ROI í‘œì‹œ")
    print("  *_bev.jpg         - BEV ë³€í™˜ ê²°ê³¼")
    print("  *_lane_mask.jpg   - ì°¨ì„  ë§ˆìŠ¤í¬")
    print("  *_overlay.jpg     - ì˜¤ë²„ë ˆì´")

if __name__ == "__main__":
    extract_debug_frames()
