#!/usr/bin/env python3
"""
ì¸í„°ë™í‹°ë¸Œ ROI ì„ íƒ ë° ì°¨ì„  ë³€ê²½ ê°ì§€ ë„êµ¬ (ìë™ ì§„í–‰ ë²„ì „)
========================================
1. 4ê°œì˜ ì ì„ í´ë¦­í•˜ì—¬ ROI ì •ì˜
2. ìë™ìœ¼ë¡œ BEV ë³€í™˜ ì ìš©
3. ì°¨ì„  ê²€ì¶œ ë° ì‹œê°í™”
4. ì°¨ì„  ë³€ê²½ ìë™ ê°ì§€
"""

import cv2
import numpy as np
from pathlib import Path
import json

# Global variables
points = []
frame_original = None

def mouse_callback(event, x, y, flags, param):
    """ë§ˆìš°ìŠ¤ í´ë¦­ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬"""
    global points, frame_original
    
    if event == cv2.EVENT_LBUTTONDOWN:
        if len(points) < 4:
            points.append([x, y])
            print(f"ì  {len(points)}: ({x}, {y})")
            
            # Draw point
            cv2.circle(frame_original, (x, y), 5, (0, 255, 0), -1)
            cv2.putText(
                frame_original, 
                str(len(points)), 
                (x + 10, y - 10),
                cv2.FONT_HERSHEY_SIMPLEX, 
                0.7, 
                (0, 255, 0), 
                2
            )
            
            # Draw line between points
            if len(points) > 1:
                cv2.line(
                    frame_original, 
                    tuple(points[-2]), 
                    tuple(points[-1]), 
                    (0, 255, 0), 
                    2
                )
            
            cv2.imshow("Select ROI Points", frame_original)
            
            if len(points) == 4:
                # Close the polygon
                cv2.line(
                    frame_original, 
                    tuple(points[-1]), 
                    tuple(points[0]), 
                    (0, 255, 0), 
                    2
                )
                cv2.imshow("Select ROI Points", frame_original)
                print("\nâœ… 4ê°œ ì  ì„ íƒ ì™„ë£Œ! 2ì´ˆ í›„ ìë™ìœ¼ë¡œ ì§„í–‰ë©ë‹ˆë‹¤...")
                cv2.waitKey(2000)  # 2ì´ˆ ëŒ€ê¸° í›„ ìë™ ì§„í–‰
                cv2.destroyAllWindows()

def select_roi_points(frame):
    """4ê°œì˜ ROI í¬ì¸íŠ¸ë¥¼ ì„ íƒ"""
    global points, frame_original
    
    points = []
    frame_original = frame.copy()
    
    cv2.namedWindow("Select ROI Points")
    cv2.setMouseCallback("Select ROI Points", mouse_callback)
    
    print("\n" + "="*60)
    print("ROI ì„ íƒ ê°€ì´ë“œ")
    print("="*60)
    print("ì°¨ì„ ì„ í¬í•¨í•˜ëŠ” ì‚¬ê°í˜• ì˜ì—­ì„ ì§€ì •í•˜ì„¸ìš”:")
    print("1. ì¢Œìƒë‹¨ (ì™¼ìª½ ìœ„)")
    print("2. ìš°ìƒë‹¨ (ì˜¤ë¥¸ìª½ ìœ„)")
    print("3. ìš°í•˜ë‹¨ (ì˜¤ë¥¸ìª½ ì•„ë˜)")
    print("4. ì¢Œí•˜ë‹¨ (ì™¼ìª½ ì•„ë˜)")
    print("\në§ˆìš°ìŠ¤ë¡œ ìˆœì„œëŒ€ë¡œ 4ê°œì˜ ì ì„ í´ë¦­í•˜ì„¸ìš”.")
    print("="*60 + "\n")
    
    cv2.imshow("Select ROI Points", frame_original)
    
    # 4ê°œ ì ì´ ì„ íƒë  ë•Œê¹Œì§€ ëŒ€ê¸°
    while len(points) < 4:
        cv2.waitKey(100)
    
    return np.float32(points)

def compute_bev_transform(src_points, dst_width=400, dst_height=600):
    """BEV ë³€í™˜ ë§¤íŠ¸ë¦­ìŠ¤ ê³„ì‚°"""
    dst_points = np.float32([
        [0, 0],                      # ì¢Œìƒë‹¨
        [dst_width, 0],              # ìš°ìƒë‹¨
        [dst_width, dst_height],     # ìš°í•˜ë‹¨
        [0, dst_height]              # ì¢Œí•˜ë‹¨
    ])
    
    M = cv2.getPerspectiveTransform(src_points, dst_points)
    return M, dst_width, dst_height

def detect_lanes_improved(bev_frame):
    """ê°œì„ ëœ ì°¨ì„  ê²€ì¶œ"""
    hsv = cv2.cvtColor(bev_frame, cv2.COLOR_BGR2HSV)
    
    # í°ìƒ‰
    lower_white = np.array([0, 0, 150])
    upper_white = np.array([180, 60, 255])
    white_mask = cv2.inRange(hsv, lower_white, upper_white)
    
    # ë…¸ë€ìƒ‰
    lower_yellow = np.array([10, 60, 60])
    upper_yellow = np.array([40, 255, 255])
    yellow_mask = cv2.inRange(hsv, lower_yellow, upper_yellow)
    
    # Edge detection
    gray = cv2.cvtColor(bev_frame, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    edges = cv2.Canny(blurred, 50, 150)
    
    # ê²°í•©
    hsv_combined = cv2.bitwise_or(white_mask, yellow_mask)
    combined = cv2.bitwise_or(hsv_combined, edges)
    
    # Morphological operations
    kernel = np.ones((5, 5), np.uint8)
    combined = cv2.morphologyEx(combined, cv2.MORPH_CLOSE, kernel)
    
    return (combined > 127).astype(np.uint8)

def find_lane_boundaries(lane_mask, roi_bottom=None):
    """ì°¨ì„  ê²½ê³„ ì°¾ê¸°"""
    if lane_mask.sum() == 0:
        return None, None, None
    
    height = lane_mask.shape[0]
    
    if roi_bottom is None:
        roi_bottom = int(height * 0.9)
    roi_top = int(height * 0.4)
    
    roi = lane_mask[roi_top:roi_bottom, :]
    
    # ê°€ì¤‘ì¹˜ (ì•„ë˜ìª½ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜)
    weights = np.linspace(0.5, 1.0, roi.shape[0])[:, np.newaxis]
    weighted_roi = roi.astype(np.float32) * weights
    column_sums = weighted_roi.sum(axis=0)
    
    lane_threshold = 3
    lane_columns = np.where(column_sums > lane_threshold)[0]
    
    if len(lane_columns) == 0:
        return None, None, None
    
    # í´ëŸ¬ìŠ¤í„°ë§
    lane_groups = []
    current_group = [lane_columns[0]]
    
    for i in range(1, len(lane_columns)):
        if lane_columns[i] - lane_columns[i-1] <= 8:
            current_group.append(lane_columns[i])
        else:
            if len(current_group) >= 2:
                lane_groups.append(current_group)
            current_group = [lane_columns[i]]
    
    if len(current_group) >= 2:
        lane_groups.append(current_group)
    
    if len(lane_groups) == 0:
        return None, None, None
    
    # ê° ê·¸ë£¹ì˜ ê°€ì¤‘ ì¤‘ì‹¬
    lane_centers = []
    for group in lane_groups:
        weights_for_group = column_sums[group]
        if weights_for_group.sum() > 0:
            weighted_center = np.average(group, weights=weights_for_group)
            lane_centers.append(int(weighted_center))
    
    if len(lane_centers) == 0:
        return None, None, None
    
    # ê°€ì¥ ì™¼ìª½ê³¼ ì˜¤ë¥¸ìª½ ì°¨ì„ 
    left_lane_x = min(lane_centers) if len(lane_centers) > 0 else None
    right_lane_x = max(lane_centers) if len(lane_centers) > 1 else None
    
    # ì°¨ì„  ì¤‘ì‹¬
    if left_lane_x is not None and right_lane_x is not None:
        lane_center_x = int((left_lane_x + right_lane_x) / 2)
    else:
        lane_center_x = None
    
    return left_lane_x, right_lane_x, lane_center_x

def process_video_with_lane_change_detection(
    video_path: Path,
    output_path: Path,
    src_points: np.ndarray,
    lane_change_start_sec: float,
    lane_change_end_sec: float,
    dst_width: int = 400,
    dst_height: int = 600
):
    """ë¹„ë””ì˜¤ ì²˜ë¦¬ ë° ì°¨ì„  ë³€ê²½ ê°ì§€"""
    print(f"\nğŸ¥ Processing: {video_path.name}")
    print(f"   Lane change: {lane_change_start_sec}s ~ {lane_change_end_sec}s")
    
    # BEV ë³€í™˜ ë§¤íŠ¸ë¦­ìŠ¤ ê³„ì‚°
    M, w, h = compute_bev_transform(src_points, dst_width, dst_height)
    
    # Open video
    cap = cv2.VideoCapture(str(video_path))
    if not cap.isOpened():
        raise RuntimeError(f"Cannot open video: {video_path}")
    
    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    # Create output writer
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    writer = cv2.VideoWriter(str(output_path), fourcc, fps, (w, h))
    
    frame_count = 0
    lane_change_detected = []
    prev_lane_center = None
    
    # ì°¨ì„  ë³€ê²½ êµ¬ê°„ í”„ë ˆì„ ë²”ìœ„
    lc_start_frame = int(lane_change_start_sec * fps)
    lc_end_frame = int(lane_change_end_sec * fps)
    
    print(f"\nì²˜ë¦¬ ì‹œì‘ (ì´ {total_frames} í”„ë ˆì„)...")
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        current_time = frame_count / fps
        
        # BEV ë³€í™˜
        bev_frame = cv2.warpPerspective(frame, M, (w, h))
        
        # ì°¨ì„  ê²€ì¶œ
        lane_mask = detect_lanes_improved(bev_frame)
        
        # ì°¨ì„  ê²½ê³„ ì°¾ê¸°
        left_x, right_x, center_x = find_lane_boundaries(lane_mask)
        
        # ì‹œê°í™”
        overlay = bev_frame.copy()
        
        # ì°¨ì„  ë§ˆìŠ¤í¬ ì˜¤ë²„ë ˆì´
        lane_mask_color = np.zeros_like(overlay)
        lane_mask_color[lane_mask > 0] = [255, 255, 255]
        overlay = cv2.addWeighted(overlay, 0.6, lane_mask_color, 0.4, 0)
        
        # ì°¨ì„  ë³€ê²½ êµ¬ê°„ í™•ì¸
        in_lane_change_zone = lc_start_frame <= frame_count <= lc_end_frame
        
        # ì°¨ì„  ê²½ê³„ ê·¸ë¦¬ê¸°
        if left_x is not None:
            cv2.line(overlay, (left_x, 0), (left_x, h), (255, 0, 0), 4)
            cv2.putText(overlay, "LEFT", (left_x - 40, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)
        
        if right_x is not None:
            cv2.line(overlay, (right_x, 0), (right_x, h), (255, 0, 0), 4)
            cv2.putText(overlay, "RIGHT", (right_x - 45, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)
        
        # ì°¨ì„  ì¤‘ì‹¬ì„ 
        if center_x is not None:
            cv2.line(overlay, (center_x, 0), (center_x, h), (0, 255, 0), 3)
            cv2.putText(overlay, "CENTER", (center_x - 45, h - 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            # ì°¨ì„  ë³€ê²½ ê°ì§€
            if prev_lane_center is not None:
                center_shift = abs(center_x - prev_lane_center)
                if center_shift > 20 and in_lane_change_zone:
                    lane_change_detected.append(frame_count)
            
            prev_lane_center = center_x
        
        # ì •ë³´ ë°•ìŠ¤
        box_height = 150
        cv2.rectangle(overlay, (5, 5), (w - 5, box_height), (0, 0, 0), -1)
        cv2.rectangle(overlay, (5, 5), (w - 5, box_height), (255, 255, 255), 2)
        
        y_offset = 30
        cv2.putText(overlay, f"Time: {current_time:.2f}s / {total_frames/fps:.2f}s", 
                   (15, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        y_offset += 30
        
        if left_x is not None and right_x is not None:
            lane_width = right_x - left_x
            cv2.putText(overlay, f"Lane Width: {lane_width}px", 
                       (15, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            y_offset += 30
        
        if center_x is not None:
            cv2.putText(overlay, f"Center: {center_x}px", 
                       (15, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            y_offset += 30
        
        # ì°¨ì„  ë³€ê²½ êµ¬ê°„ í‘œì‹œ
        if in_lane_change_zone:
            cv2.putText(overlay, ">>> LANE CHANGE ZONE <<<", 
                       (15, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 165, 255), 2)
        
        # ê°ì§€ëœ ì°¨ì„  ë³€ê²½ í‘œì‹œ
        if frame_count in lane_change_detected[-10:]:
            cv2.rectangle(overlay, (10, h - 60), (w - 10, h - 10), (0, 0, 255), -1)
            cv2.putText(overlay, "!!! CHANGE DETECTED !!!", 
                       (w//2 - 120, h - 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
        
        writer.write(overlay)
        
        frame_count += 1
        if frame_count % 30 == 0:
            status = "LANE_CHANGE" if in_lane_change_zone else "NORMAL"
            print(f"  Frame {frame_count}/{total_frames} ({current_time:.1f}s) [{status}]")
    
    cap.release()
    writer.release()
    
    print(f"\nâœ… Output saved: {output_path}")
    print(f"   Total frames: {total_frames}")
    print(f"   Lane changes detected: {len(lane_change_detected)} times")
    
    return lane_change_detected

def save_roi_config(video_name: str, points: np.ndarray, output_dir: Path):
    """ROI ì„¤ì • ì €ì¥"""
    config_path = output_dir / f"{video_name}_roi_config.json"
    
    config = {
        "video_name": video_name,
        "roi_points": points.tolist(),
        "description": "ROI points: top-left, top-right, bottom-right, bottom-left"
    }
    
    with open(config_path, 'w') as f:
        json.dump(config, f, indent=2)
    
    print(f"ğŸ’¾ ROI config saved: {config_path}")

def load_roi_config(config_path: Path):
    """ROI ì„¤ì • ë¡œë“œ"""
    if not config_path.exists():
        return None
    
    with open(config_path, 'r') as f:
        config = json.load(f)
    
    return np.float32(config['roi_points'])

def main():
    print("="*70)
    print(" ì¸í„°ë™í‹°ë¸Œ ROI ì„ íƒ ë° ì°¨ì„  ë³€ê²½ ê°ì§€ ë„êµ¬")
    print("="*70)
    
    # ë¹„ë””ì˜¤ ê²½ë¡œ
    data_dir = Path(__file__).resolve().parent.parent / "Data"
    output_dir = Path(__file__).resolve().parent
    
    videos = [
        {
            "path": data_dir / "ì´ë²¤íŠ¸ 4.mp4",
            "name": "ì´ë²¤íŠ¸ 4",
            "lane_change_start": 4.0,
            "lane_change_end": 6.0,
            "description": "ì˜¤ë¥¸ìª½ â†’ ì™¼ìª½ ì°¨ì„  ë³€ê²½"
        },
        {
            "path": data_dir / "ì´ë²¤íŠ¸ 5.mp4",
            "name": "ì´ë²¤íŠ¸ 5",
            "lane_change_start": 5.0,
            "lane_change_end": 8.0,
            "description": "ì™¼ìª½ â†’ ì˜¤ë¥¸ìª½ ì°¨ì„  ë³€ê²½"
        }
    ]
    
    for video_info in videos:
        print(f"\n{'='*70}")
        print(f"ğŸ¬ {video_info['name']}: {video_info['description']}")
        print(f"   ì°¨ì„  ë³€ê²½ êµ¬ê°„: {video_info['lane_change_start']}s ~ {video_info['lane_change_end']}s")
        print(f"{'='*70}")
        
        # ë¹„ë””ì˜¤ ë¡œë“œ
        video_path = video_info['path']
        cap = cv2.VideoCapture(str(video_path))
        
        # ì²« í”„ë ˆì„ ê°€ì ¸ì˜¤ê¸°
        ret, frame = cap.read()
        cap.release()
        
        if not ret:
            print(f"âŒ Failed to read video: {video_path}")
            continue
        
        # ROI ì„¤ì • ë¡œë“œ ë˜ëŠ” ì„ íƒ
        config_path = output_dir / f"{video_info['name']}_roi_config.json"
        roi_points = load_roi_config(config_path)
        
        if roi_points is not None:
            print(f"\nâœ… Loaded ROI config from: {config_path}")
            print(f"   Points: {roi_points.tolist()}")
            use_existing = input("ê¸°ì¡´ ROI ì‚¬ìš©? (y/n, ê¸°ë³¸ y): ").strip().lower()
            
            if use_existing == 'n':
                roi_points = select_roi_points(frame)
                save_roi_config(video_info['name'], roi_points, output_dir)
        else:
            print(f"\nâš ï¸  ROI config not found. Please select ROI points.")
            roi_points = select_roi_points(frame)
            save_roi_config(video_info['name'], roi_points, output_dir)
        
        # ë¹„ë””ì˜¤ ì²˜ë¦¬
        output_path = output_dir / f"{video_info['name']}_interactive.mp4"
        
        lane_changes = process_video_with_lane_change_detection(
            video_path,
            output_path,
            roi_points,
            video_info['lane_change_start'],
            video_info['lane_change_end'],
            dst_width=400,
            dst_height=600
        )
        
        print(f"\nğŸ“Š ë¶„ì„ ê²°ê³¼:")
        print(f"   ì°¨ì„  ë³€ê²½ ê°ì§€ íšŸìˆ˜: {len(lane_changes)}")
        if lane_changes:
            fps = 30
            times = [f / fps for f in lane_changes]
            print(f"   ê°ì§€ ì‹œê°„: {min(times):.2f}s ~ {max(times):.2f}s")
    
    print("\n" + "="*70)
    print("âœ… ëª¨ë“  ë¹„ë””ì˜¤ ì²˜ë¦¬ ì™„ë£Œ!")
    print("="*70)

if __name__ == "__main__":
    main()
